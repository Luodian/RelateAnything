{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9da2aa1",
   "metadata": {},
   "source": [
    "# Training RelateAnything with PSG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from segment_anything import build_sam, SamPredictor, SamAutomaticMaskGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b9430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = SamPredictor(build_sam(checkpoint=\"./segment_anything/checkpoints/sam_vit_h_4b8939.pth\"))\n",
    "mask_generator = SamAutomaticMaskGenerator(build_sam(checkpoint=\"./segment_anything/checkpoints/sam_vit_h_4b8939.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2c43b4",
   "metadata": {},
   "source": [
    "### Get PSG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd864b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from openpsg.utils.vis_tools.datasets import coco_dir\n",
    "from openpsg.utils.vis_tools.preprocess import load_json\n",
    "\n",
    "from detectron2.data.detection_utils import read_image\n",
    "from detectron2.utils.colormap import colormap\n",
    "from panopticapi.utils import rgb2id\n",
    "\n",
    "def get_colormap(num_colors: int):\n",
    "    return (np.resize(colormap(), (num_colors, 3))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602d1ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working path as home dir to easy access data\n",
    "psg_dataset_file = load_json(Path(\"data/psg/psg.json\"))\n",
    "print('keys: ', list(psg_dataset_file.keys()))\n",
    "\n",
    "psg_thing_cats = psg_dataset_file['thing_classes']\n",
    "psg_stuff_cats = psg_dataset_file['stuff_classes']\n",
    "psg_obj_cats = psg_thing_cats + psg_stuff_cats\n",
    "psg_rel_cats = psg_dataset_file['predicate_classes']\n",
    "psg_dataset = {d[\"image_id\"]: d for d in psg_dataset_file['data']}\n",
    "# psg_dataset_coco_id = {d[\"coco_image_id\"]: d for d in psg_dataset_file['data']}\n",
    "\n",
    "print('Number of images: {}'.format(len(psg_dataset)))\n",
    "print('# Object Classes: {}'.format(len(psg_obj_cats)))\n",
    "print('# Relation Classes: {}'.format(len(psg_rel_cats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5394a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_img_id = '2346957'\n",
    "data = psg_dataset[example_img_id]\n",
    "data['relations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57fbc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show origin image\n",
    "image = read_image(coco_dir / data[\"file_name\"], format=\"RGB\")\n",
    "seg_map = read_image(coco_dir / data[\"pan_seg_file_name\"], format=\"RGB\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(image)\n",
    "axs[0].set_title(\"Original Image\")\n",
    "axs[1].imshow(seg_map)\n",
    "axs[1].set_title(\"Segment Map\")\n",
    "\n",
    "# Hide the x and y axis labels for both subplots\n",
    "for ax in axs:\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "# Display the subplots\n",
    "plt.show()\n",
    "\n",
    "# show seg annotations\n",
    "seg_map = rgb2id(seg_map)\n",
    "print('Segments IDs: ', np.unique(seg_map))\n",
    "print('Segments Annotations: ')\n",
    "pprint.pprint(data[\"segments_info\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802de955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get seperate masks\n",
    "gt_masks = []\n",
    "labels_coco = []\n",
    "for i, s in enumerate(data[\"segments_info\"]):\n",
    "    label = psg_obj_cats[s[\"category_id\"]]\n",
    "    labels_coco.append(label)\n",
    "    gt_masks.append(seg_map == s[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "pilimage = Image.open(coco_dir / data[\"file_name\"])\n",
    "width, height = pilimage.size\n",
    "full_area = width * height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622cbe61",
   "metadata": {},
   "source": [
    "### Segment Everything\n",
    "\n",
    "In this part, we have sam_feats as all masks features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87900ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_masks = mask_generator.generate(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace4d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48adbcef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_masks = [d for d in sam_masks if d['area'] > 0.03 * full_area]\n",
    "print('number of masks left:', len(filtered_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec5a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(mask1, mask2):\n",
    "    intersection = np.logical_and(mask1, mask2)\n",
    "    union = np.logical_or(mask1, mask2)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    return iou_score\n",
    "\n",
    "def sort_and_deduplicate(sam_masks, iou_threshold=0.8):\n",
    "    # Sort the sam_masks list based on the area value\n",
    "    sorted_masks = sorted(sam_masks, key=lambda x: x['area'], reverse=True)\n",
    "\n",
    "    # Deduplicate masks based on the given iou_threshold\n",
    "    filtered_masks = []\n",
    "    for mask in sorted_masks:\n",
    "        duplicate = False\n",
    "        for filtered_mask in filtered_masks:\n",
    "            if iou(mask['segmentation'], filtered_mask['segmentation']) > iou_threshold:\n",
    "                duplicate = True\n",
    "                break\n",
    "\n",
    "        if not duplicate:\n",
    "            filtered_masks.append(mask)\n",
    "\n",
    "    return filtered_masks\n",
    "\n",
    "# Example usage\n",
    "filtered_masks = sort_and_deduplicate(filtered_masks)\n",
    "print('number of masks left:', len(filtered_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08592e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddup_masks = sort_and_deduplicate(sam_masks)\n",
    "print('number of deduplicated masks:', len(ddup_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d02acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anns(anns, color='auto'):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "    polygons = []\n",
    "    color = []\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        img = np.ones((m.shape[0], m.shape[1], 3))\n",
    "        color_mask = np.random.random((1, 3)).tolist()[0]\n",
    "        if color == 'auto':\n",
    "            for i in range(3):\n",
    "                img[:,:,i] = color_mask[i]\n",
    "        else:\n",
    "            for i in range(3):\n",
    "                img[:,:,0] = 1\n",
    "                img[:,:,1] = 0\n",
    "                img[:,:,2] = 0\n",
    "    return np.dstack((img, m*0.35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e962e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', \n",
    "               s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', \n",
    "               s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1bd8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Calculate the number of rows needed\n",
    "num_rows = math.ceil(len(ddup_masks) / 5)\n",
    "\n",
    "# Create the subplots\n",
    "fig, axs = plt.subplots(num_rows, 5, figsize=(15, 3*num_rows))\n",
    "\n",
    "# Loop through the images and add them to the subplots\n",
    "for i, mask in enumerate(ddup_masks):\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    \n",
    "    axs[row, col].imshow(img, alpha=0.3)\n",
    "    axs[row, col].imshow(show_anns(ddup_masks[i:i+1], 'red'))\n",
    "    axs[row, col].axis('off')\n",
    "    axs[row, col].set_title(i)\n",
    "    \n",
    "\n",
    "# Display the subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d85415",
   "metadata": {},
   "source": [
    "### GT Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb92fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705aa160",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_feats = []\n",
    "\n",
    "for gt_mask in gt_masks:\n",
    "    max_iou = 0\n",
    "    best_feat = None\n",
    "\n",
    "    for mask_dict in ddup_masks:\n",
    "        current_iou = iou(gt_mask, mask_dict['segmentation'])\n",
    "\n",
    "        if current_iou > max_iou:\n",
    "            max_iou = current_iou\n",
    "            best_feat = mask_dict['feat']\n",
    "\n",
    "    gt_feats.append(best_feat)\n",
    "\n",
    "gt_feats = np.array(gt_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c98bea",
   "metadata": {},
   "source": [
    "### Gather all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b9d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['relations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5fcc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gt_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349c11ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(psg_dataset.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_entry = {'id': id_num,\n",
    "              'feat': gt_feats,\n",
    "              'relations': data['relations'],\n",
    "              'is_train': id_num in psg_dataset_file['test_image_ids'],\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928e49ec",
   "metadata": {},
   "source": [
    "### Set training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b797652",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c09b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('feats/save_dict_2346957.npz', allow_pickle=True) as data:\n",
    "    print(len(data['feat']))\n",
    "    print(data['relations'])\n",
    "    for i, token in enumerate(data['feat']):\n",
    "        print(i)\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d8fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# List all npz files in the feats directory\n",
    "file_list = glob.glob(\"feats/save_dict_*.npz\")\n",
    "\n",
    "train_data = []\n",
    "train_label = []\n",
    "\n",
    "test_data = []\n",
    "test_label = []\n",
    "\n",
    "for file in tqdm(file_list):\n",
    "    with np.load(file, allow_pickle=True) as data:\n",
    "        pairs_and_labels = []\n",
    "        for relation in data['relations']:\n",
    "            feat_id_1, feat_id_2, label = relation\n",
    "            feature_1 = np.array(data['feat'][feat_id_1])\n",
    "            feature_2 = np.array(data['feat'][feat_id_2])\n",
    "            try:\n",
    "                feature_pair = np.concatenate((feature_1, feature_2))\n",
    "                if data['is_train']:\n",
    "                    train_data.append(feature_pair)\n",
    "                    train_label.append(label)\n",
    "                else:\n",
    "                    test_data.append(feature_pair)\n",
    "                    test_label.append(label)\n",
    "            except ValueError:\n",
    "                print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7bac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train_data)\n",
    "train_label = np.array(train_label)\n",
    "print('train data size:', train_data.shape, 'label size: ', train_label.shape)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_label = np.array(test_label)\n",
    "print('test data size:', test_data.shape, 'label size: ', test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('relation_feat', \n",
    "         train_data=train_data, train_label=train_label, \n",
    "         test_data=test_data, test_label=test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f9ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81add256",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, dropout_prob=0.1):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcd03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "input_size = 512\n",
    "hidden_size = 256\n",
    "num_classes = 56\n",
    "model = MLP(input_size, hidden_size, num_classes)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b3517",
   "metadata": {},
   "source": [
    "### Segment with Prompt\n",
    "\n",
    "In this section, we extract the mask feature as feats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9740f614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_name = './images/dog.jpg'\n",
    "\n",
    "image = cv2.imread(image_name)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "pilimage = Image.open(image_name)\n",
    "width, height = pilimage.size\n",
    "full_area = width * height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b181c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = SamPredictor(build_sam(checkpoint=\"./segment_anything/checkpoints/sam_vit_h_4b8939.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2585704",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.set_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b8b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog\n",
    "input_point = np.array([[200, 375]])\n",
    "input_label = np.array([1])\n",
    "\n",
    "# bowl\n",
    "# input_point = np.array([[600, 200]])\n",
    "# input_label = np.array([1])\n",
    "\n",
    "# human\n",
    "# input_point = np.array([[700, 50]])\n",
    "# input_label = np.array([1])\n",
    "\n",
    "# ground\n",
    "# input_point = np.array([[500, 400]])\n",
    "# input_label = np.array([1])\n",
    "\n",
    "plt.imshow(image)\n",
    "show_points(input_point, input_label, plt.gca())\n",
    "# plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "mask1, score1, logit1, feat1 = predictor.predict(point_coords=input_point,\n",
    "                                                 point_labels=input_label,\n",
    "                                                 multimask_output=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0cbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog\n",
    "# input_point = np.array([[200, 375]])\n",
    "# input_label = np.array([1])\n",
    "\n",
    "# bowl\n",
    "# input_point = np.array([[600, 200]])\n",
    "# input_label = np.array([1])\n",
    "\n",
    "# human\n",
    "# input_point = np.array([[700, 50]])\n",
    "# input_label = np.array([1])\n",
    "\n",
    "# sofa\n",
    "input_point = np.array([[150, 100]])\n",
    "input_label = np.array([1])\n",
    "\n",
    "# # ground\n",
    "# input_point = np.array([[500, 400]])\n",
    "# input_label = np.array([1])\n",
    "\n",
    "plt.imshow(image)\n",
    "show_points(input_point, input_label, plt.gca())\n",
    "# plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "mask2, score2, logit2, feat2 = predictor.predict(point_coords=input_point,\n",
    "                                                 point_labels=input_label,\n",
    "                                                 multimask_output=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c51f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_input = torch.cat((feat1, feat2), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacb5ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_classes = [\n",
    "    'over', 'in front of', 'beside', 'on', 'in', 'attached to', 'hanging from', 'on back of', 'falling off', \n",
    "    'going down', 'painted on', 'walking on', 'running on', 'crossing', 'standing on', 'lying on', 'sitting on', \n",
    "    'flying over', 'jumping over', 'jumping from', 'wearing', 'holding', 'carrying', 'looking at', 'guiding', \n",
    "    'kissing', 'eating', 'drinking', 'feeding', 'biting', 'catching', 'picking', 'playing with', 'chasing', \n",
    "    'climbing', 'cleaning', 'playing', 'touching', 'pushing', 'pulling', 'opening', 'cooking', 'talking to', \n",
    "    'throwing', 'slicing', 'driving', 'riding', 'parked on', 'driving on', 'about to hit', 'kicking', 'swinging', \n",
    "    'entering', 'exiting', 'enclosing', 'leaning on']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48db342",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(concat_input)\n",
    "topk_indices = torch.argsort(-output).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617a6643",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_rel = [relation_classes[indice] for indice in topk_indices][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1486d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f075d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_output = torch.sigmoid(output)\n",
    "rounded_output = torch.round(sigmoid_output * 100) / 100\n",
    "print(rounded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b15cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)\n",
    "    show_mask(mask, plt.gca())\n",
    "    show_points(input_point, input_label, plt.gca())\n",
    "    plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:relate_anything]",
   "language": "python",
   "name": "conda-env-relate_anything-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
